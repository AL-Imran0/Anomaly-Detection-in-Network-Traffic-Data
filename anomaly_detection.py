# -*- coding: utf-8 -*-
"""Anomaly Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gcn8a0l48Dm99NMyJ6Pfey4UvpocM6A_
"""

!pip install numpy pandas scikit-learn keras matplotlib

!pip install pyod

!pip install numpy pandas scikit-learn keras matplotlib seaborn

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.neighbors import LocalOutlierFactor
from sklearn.covariance import EllipticEnvelope
from sklearn.mixture import GaussianMixture
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from keras.models import Sequential
from keras.layers import Dense
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import time

np.random.seed(42)

normal_traffic = np.random.randn(2000, 5)

anomalous_traffic = np.random.uniform(low=4, high=6, size=(200, 5))

X_synthetic = np.vstack([normal_traffic, anomalous_traffic])

y_synthetic = np.ones(X_synthetic.shape[0])
y_synthetic[-200:] = -1

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_synthetic)

iso_forest = IsolationForest(random_state=42)
y_pred_iso = iso_forest.fit_predict(X_scaled)

oc_svm = OneClassSVM(nu=0.1, gamma='scale')
y_pred_svm = oc_svm.fit_predict(X_scaled)

lof = LocalOutlierFactor(n_neighbors=20)
y_pred_lof = lof.fit_predict(X_scaled)

ee = EllipticEnvelope()
y_pred_ee = ee.fit_predict(X_scaled)

def build_autoencoder(input_dim):
    model = Sequential()
    model.add(Dense(64, activation='relu', input_dim=input_dim))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(input_dim, activation='sigmoid'))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

autoencoder = build_autoencoder(X_scaled.shape[1])
autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=32, validation_data=(X_scaled, X_scaled))

reconstructed = autoencoder.predict(X_scaled)
mse = np.mean(np.square(X_scaled - reconstructed), axis=1)
outliers_autoencoder = mse > np.percentile(mse, 95)

gmm = GaussianMixture(n_components=2, random_state=42)
y_pred_gmm = gmm.fit_predict(X_scaled)

kmeans = KMeans(n_clusters=2, random_state=42)
y_pred_kmeans = kmeans.fit_predict(X_scaled)

z_scores = np.abs((X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0))
outliers_zscore = (z_scores > 3).any(axis=1)

mean_normal = X_scaled[y_synthetic == 1].mean(axis=0)
std_normal = X_scaled[y_synthetic == 1].std(axis=0)

control_limits_upper = mean_normal + 3 * std_normal
control_limits_lower = mean_normal - 3 * std_normal

spc_outliers = np.any((X_scaled < control_limits_lower) | (X_scaled > control_limits_upper), axis=1)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
X_reconstructed = pca.inverse_transform(X_pca)
reconstruction_error = np.mean(np.square(X_scaled - X_reconstructed), axis=1)
y_pred_pca = reconstruction_error > np.percentile(reconstruction_error, 95)

print("\nIsolation Forest Classification Report:")
print(classification_report(y_synthetic, y_pred_iso))

print("\nOne-Class SVM Classification Report:")
print(classification_report(y_synthetic, y_pred_svm))

print("\nLOF Classification Report:")
print(classification_report(y_synthetic, y_pred_lof))

print("\nElliptic Envelope Classification Report:")
print(classification_report(y_synthetic, y_pred_ee))

print("\nAutoencoder Classification Report:")
print(classification_report(y_synthetic, outliers_autoencoder))

print("\nGMM Classification Report:")
print(classification_report(y_synthetic, y_pred_gmm))

print("\nk-Means Classification Report:")
print(classification_report(y_synthetic, y_pred_kmeans))

print("\nZ-Score Classification Report:")
print(classification_report(y_synthetic, outliers_zscore))

print("\nSPC Classification Report:")
print(classification_report(y_synthetic, spc_outliers))

print("\nPCA Classification Report:")
print(classification_report(y_synthetic, y_pred_pca))

plt.figure(figsize=(12, 8))

plt.scatter(X_scaled[y_synthetic == 1][:, 0], X_scaled[y_synthetic == 1][:, 1], label='Normal', color='blue', alpha=0.6)

plt.scatter(X_scaled[y_synthetic == -1][:, 0], X_scaled[y_synthetic == -1][:, 1], label='Anomaly', color='red', alpha=0.8)

plt.title("Anomaly Detection: Normal vs Anomalous Points")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.show()

sns.heatmap(confusion_matrix(y_synthetic, y_pred_iso), annot=True, fmt="d", cmap='Blues')
plt.title("Confusion Matrix for Isolation Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

print("\n--- Project Summary ---")
print("All algorithms successfully applied to detect anomalies in network traffic data.")

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 8))

plt.scatter(X_scaled[y_synthetic == 1][:, 0], X_scaled[y_synthetic == 1][:, 1],
            label='Normal', color='blue', alpha=0.6)

plt.scatter(X_scaled[y_synthetic == -1][:, 0], X_scaled[y_synthetic == -1][:, 1],
            label='Anomaly', color='red', alpha=0.8)

plt.title("Anomaly Detection: Normal vs Anomalous Points (2D Plot)")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.show()

plt.figure(figsize=(10, 8))

plt.hist2d(X_scaled[:, 0], X_scaled[:, 1], bins=50, cmap='Blues', alpha=0.7)
plt.colorbar(label='Density')
plt.title("2D Histogram of Network Traffic Data (Feature 1 vs Feature 2)")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

plt.figure(figsize=(12, 8))

sns.boxplot(data=X_scaled, palette='Set2')
plt.title("Box Plot for Each Feature (Outliers Detection)")
plt.xlabel("Features")
plt.ylabel("Feature Values")
plt.show()

plt.figure(figsize=(10, 8))

correlation_matrix = np.corrcoef(X_scaled.T)
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title("Correlation Heatmap of Features")
plt.show()